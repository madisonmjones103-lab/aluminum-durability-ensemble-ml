{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXPbV8RVVGz7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Installing packages and setting up environment\n",
        "\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q scikit-learn==1.6.1\n",
        "!pip install -q xgboost lightgbm catboost\n",
        "!pip install -q mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Boosted libraries\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "hUPUqB_xrQ75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Designating pathnames\n",
        "\n",
        "TRAIN_PATH = \"/content/aluminum_coldRoll_train.csv\"\n",
        "TEST_PATH = \"/content/aluminum_coldRoll_testNoY.csv\"\n",
        "OUTPUT_PATH = \"/content/Team17_Submission.csv\""
      ],
      "metadata": {
        "id": "oI9wD6KveZHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading .csv files\n",
        "\n",
        "df_train = pd.read_csv(\"/content/aluminum_coldRoll_train.csv\")\n",
        "df_test = pd.read_csv(\"/content/aluminum_coldRoll_testNoY.csv\")"
      ],
      "metadata": {
        "id": "DPlpB40SnN6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical and numeric columns/predictors\n",
        "\n",
        "TARGET = \"y_passXtremeDurability\"\n",
        "ID_col = 'ID'\n",
        "\n",
        "X = df_train.drop(columns=[TARGET]).copy()\n",
        "y = df_train[TARGET].copy()\n",
        "X_test = df_test.copy()\n",
        "\n",
        "cat_cols = X.select_dtypes(include=[object, 'category']).columns.tolist()\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()"
      ],
      "metadata": {
        "id": "GQI2KF2bnV7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up OneHotEncoder for tree boosters\n",
        "\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "('num', num_imputer, num_cols),\n",
        "('cat', Pipeline([('imp', cat_imputer), ('ohe', ohe)]), cat_cols)\n",
        "], remainder='drop')\n",
        "\n",
        "preprocessor.fit(X)\n",
        "\n",
        "# Transforming datasets for models that need OneHotEncoder for categorical variables\n",
        "\n",
        "X_ohe = preprocessor.transform(X)\n",
        "X_test_ohe = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "tFp4_ydRot9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting out of fold train predictions and test predictions averaged over folds\n",
        "def get_oof_predictions(clf, X, y, X_test, n_splits=10, random_state=42, use_proba=True, fit_params=None):\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    oof_train = np.zeros(X.shape[0])\n",
        "    oof_test = np.zeros((X_test.shape[0], n_splits))\n",
        "\n",
        "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "        X_tr, X_val = X[train_idx], X[val_idx]\n",
        "        y_tr, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        # Fitting\n",
        "        if fit_params:\n",
        "            clf.fit(X_tr, y_tr, **fit_params)\n",
        "        else:\n",
        "            clf.fit(X_tr, y_tr)\n",
        "\n",
        "        # Predicting\n",
        "        if use_proba and hasattr(clf, 'predict_proba'):\n",
        "            oof_train[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
        "            oof_test[:, i] = clf.predict_proba(X_test)[:, 1]\n",
        "        elif hasattr(clf, 'decision_function'):\n",
        "            oof_train[val_idx] = clf.decision_function(X_val)\n",
        "            oof_test[:, i] = clf.decision_function(X_test)\n",
        "        else:\n",
        "            oof_train[val_idx] = clf.predict(X_val)\n",
        "            oof_test[:, i] = clf.predict(X_test)\n",
        "\n",
        "        print(f\"Fold {i+1}/{n_splits} done.\")\n",
        "\n",
        "    # Averaging test predictions\n",
        "    oof_test_mean = oof_test.mean(axis=1)\n",
        "\n",
        "    return oof_train, oof_test_mean"
      ],
      "metadata": {
        "id": "e4-ifVW1pngw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Designating parameters for models\n",
        "\n",
        "cat_features_idx = [X.columns.get_loc(c) for c in cat_cols] if len(cat_cols) > 0 else []\n",
        "\n",
        "cat_params = dict(\n",
        "iterations=1200,\n",
        "learning_rate=0.03,\n",
        "depth=8,\n",
        "eval_metric='AUC',\n",
        "random_seed=42,\n",
        "verbose=0,\n",
        "early_stopping_rounds=100\n",
        ")\n",
        "\n",
        "lgbm_params = dict(\n",
        "n_estimators=1200,\n",
        "learning_rate=0.03,\n",
        "num_leaves=64,\n",
        "max_depth=-1,\n",
        "subsample=0.8,\n",
        "colsample_bytree=0.8,\n",
        "class_weight='balanced',\n",
        "random_state=42\n",
        ")\n",
        "\n",
        "xgb_params = dict(\n",
        "n_estimators=1200,\n",
        "learning_rate=0.03,\n",
        "max_depth=8,\n",
        "subsample=0.8,\n",
        "colsample_bytree=0.8,\n",
        "use_label_encoder=False,\n",
        "eval_metric='logloss',\n",
        "random_state=42,\n",
        "tree_method='hist'\n",
        ")\n",
        "\n",
        "rf_params = dict(\n",
        "n_estimators=500,\n",
        "max_depth=12,\n",
        "min_samples_leaf=2,\n",
        "class_weight='balanced',\n",
        "random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Initializing models\n",
        "\n",
        "cat_model = CatBoostClassifier(**cat_params)\n",
        "lgbm_model = LGBMClassifier(**lgbm_params)\n",
        "xgb_model = XGBClassifier(**xgb_params)\n",
        "rf_model = RandomForestClassifier(**rf_params)"
      ],
      "metadata": {
        "id": "r5M5DvBRtAwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation\n",
        "\n",
        "def fit(self, X, y, **kwargs):\n",
        "  self.model.fit(X, y, **kwargs)\n",
        "\n",
        "def predict_proba(self, X):\n",
        "  return self.model.predict_proba(X)\n",
        "\n",
        "def get_oof_catboost(cat_model, X_df, y, X_test_df, n_splits=10, random_state=42):\n",
        "  skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "  oof = np.zeros(X_df.shape[0])\n",
        "  oof_test = np.zeros((X_test_df.shape[0], n_splits))\n",
        "\n",
        "  for i, (train_idx, val_idx) in enumerate(skf.split(X_df, y)):\n",
        "    X_tr = X_df.iloc[train_idx]\n",
        "    y_tr = y.iloc[train_idx]\n",
        "    X_val = X_df.iloc[val_idx]\n",
        "\n",
        "    cat_model.fit(X_tr, y_tr, cat_features=cat_cols, eval_set=(X_val, y.iloc[val_idx]))\n",
        "    oof[val_idx] = cat_model.predict_proba(X_val)[:, 1]\n",
        "    oof_test[:, i] = cat_model.predict_proba(X_test_df)[:, 1]\n",
        "\n",
        "  return oof, oof_test.mean(axis=1)"
      ],
      "metadata": {
        "id": "Z8I1R9GxtJs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up predictions from base models\n",
        "\n",
        "X_ohe_arr = np.array(X_ohe)\n",
        "X_test_ohe_arr = np.array(X_test_ohe)\n",
        "y_arr = np.array(y)"
      ],
      "metadata": {
        "id": "7Jz3nSFT3Dhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run LGBM OOF\n",
        "\n",
        "lgbm_oof_train, lgbm_oof_test = get_oof_predictions(\n",
        "    lgbm_model, X_ohe_arr, y_arr, X_test_ohe_arr, n_splits=10\n",
        ")\n",
        "print(roc_auc_score(y_arr, lgbm_oof_train))\n",
        "\n",
        "# Run XGB OOF\n",
        "\n",
        "xgb_oof_train, xgb_oof_test = get_oof_predictions(\n",
        "    xgb_model, X_ohe_arr, y_arr, X_test_ohe_arr, n_splits=10\n",
        ")\n",
        "print(roc_auc_score(y_arr, xgb_oof_train))\n",
        "\n",
        "# Run RandomForest OOF\n",
        "\n",
        "rf_oof_train, rf_oof_test = get_oof_predictions(\n",
        "    rf_model, X_ohe_arr, y_arr, X_test_ohe_arr, n_splits=10\n",
        ")\n",
        "print(roc_auc_score(y_arr, rf_oof_train))\n"
      ],
      "metadata": {
        "id": "edG5jQnVyAH6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run CatBoost OOF\n",
        "\n",
        "cat_oof_train, cat_oof_test = get_oof_catboost(cat_model, X, y, X_test, n_splits=10)\n",
        "print(roc_auc_score(y, cat_oof_train))"
      ],
      "metadata": {
        "id": "WZl92eojxTPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking dataset\n",
        "\n",
        "stack_train = np.vstack([cat_oof_train, lgbm_oof_train, xgb_oof_train, rf_oof_train]).T\n",
        "stack_test = np.vstack([cat_oof_test, lgbm_oof_test, xgb_oof_test, rf_oof_test]).T"
      ],
      "metadata": {
        "id": "h24CjPNaAJEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibrating meta learner\n",
        "\n",
        "meta_clf = LogisticRegression(max_iter=2000)\n",
        "meta_clf.fit(stack_train, y)\n",
        "meta_train_pred = meta_clf.predict_proba(stack_train)[:, 1]\n",
        "print('Meta-train AUC:', roc_auc_score(y, meta_train_pred))\n",
        "\n",
        "calibrator = CalibratedClassifierCV(\n",
        "    estimator=LogisticRegression(max_iter=2000),\n",
        "    cv=3,\n",
        "    method='isotonic'\n",
        ")\n",
        "\n",
        "calibrator.fit(stack_train, y)\n",
        "meta_calibrated_pred = calibrator.predict_proba(stack_train)[:, 1]\n",
        "print('Meta (calibrated) train AUC:', roc_auc_score(y, meta_calibrated_pred))\n",
        "\n",
        "# Use calibrated meta predictions on test\n",
        "\n",
        "meta_test_pred = calibrator.predict_proba(stack_test)[:, 1]\n",
        "meta_test_pred = np.clip(meta_test_pred, 1e-6, 1 - 1e-6)"
      ],
      "metadata": {
        "id": "XGNj72PbAQbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "'ID': X_test[ID_col],\n",
        "'y_passXtremeDurability': meta_test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"Saved submission to {OUTPUT_PATH}\")"
      ],
      "metadata": {
        "id": "iPHczEjaAme0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}